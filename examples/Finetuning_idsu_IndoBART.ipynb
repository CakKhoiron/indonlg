{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68fb35cd-49a2-4c56-9b88-c5f59e8266b1",
   "metadata": {},
   "source": [
    "# Finetuning ID -> SU using IndoBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dbf957d-5ecd-4bb3-9783-924e3616b596",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../')\n",
    "os.chdir('../')\n",
    "\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from transformers import MBartForConditionalGeneration\n",
    "\n",
    "from indobenchmark import IndoNLGTokenizer\n",
    "from utils.train_eval import train, evaluate\n",
    "from utils.metrics import generation_metrics_fn\n",
    "from utils.forward_fn import forward_generation\n",
    "from utils.data_utils import MachineTranslationDataset, GenerationDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0598507a-1fc4-433e-bbce-1d5356b6e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# common functions\n",
    "###\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "def count_param(module, trainable=False):\n",
    "    if trainable:\n",
    "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in module.parameters())\n",
    "    \n",
    "# Set random seed\n",
    "# set_seed(26092020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9ab88-51d3-42dc-b982-954141c25270",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed9ab7a-a6d6-4b02-a864-ce18fbcbba1a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MBartForConditionalGeneration(\n",
       "  (model): MBartModel(\n",
       "    (shared): Embedding(40004, 768, padding_idx=1)\n",
       "    (encoder): MBartEncoder(\n",
       "      (embed_tokens): Embedding(40004, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MBartEncoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): MBartDecoder(\n",
       "      (embed_tokens): Embedding(40004, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MBartDecoderLayer(\n",
       "          (self_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=40004, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_model = MBartForConditionalGeneration.from_pretrained('indobenchmark/indobart')\n",
    "tokenizer = IndoNLGTokenizer.from_pretrained('indobenchmark/indobart')\n",
    "\n",
    "# bart_model = MBartForConditionalGeneration.from_pretrained('indobenchmark/indobart-v2')\n",
    "# tokenizer = IndoNLGTokenizer.from_pretrained('indobenchmark/indobart-v2')\n",
    "\n",
    "model = bart_model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2992106-cf65-4804-a393-d0a49026a659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131543040"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_param(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04ba0a-b746-4188-9f2c-4366a5dd5882",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a860b4-72b7-4432-8d32-4e6aea69ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs and args\n",
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.9\n",
    "lower = True\n",
    "step_size = 1\n",
    "beam_size = 5\n",
    "max_norm = 10\n",
    "early_stop = 5\n",
    "\n",
    "max_seq_len = 512\n",
    "grad_accumulate = 1\n",
    "no_special_token = False\n",
    "swap_source_target = True\n",
    "model_type = 'indo-bart'\n",
    "valid_criterion = 'SacreBLEU'\n",
    "\n",
    "separator_id = 4\n",
    "speaker_1_id = 5\n",
    "speaker_2_id = 6\n",
    "\n",
    "train_batch_size = 8\n",
    "valid_batch_size = 8\n",
    "test_batch_size = 8\n",
    "\n",
    "source_lang = \"[indonesian]\"\n",
    "target_lang = \"[sundanese]\"\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "src_lid = tokenizer.special_tokens_to_ids[source_lang]\n",
    "tgt_lid = tokenizer.special_tokens_to_ids[target_lang]\n",
    "\n",
    "model.config.decoder_start_token_id = tgt_lid\n",
    "\n",
    "# Make sure cuda is deterministic\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# create directory\n",
    "model_dir = './save/MT_SUNIBS_INZNTV/example_id_su'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "device = 'cuda0'\n",
    "# set a specific cuda device\n",
    "if \"cuda\" in device:\n",
    "    torch.cuda.set_device(int(device[4:]))\n",
    "    device = \"cuda\"\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b2d855-7293-4577-861b-2235b7ac59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = './dataset/MT_SUNIBS_INZNTV/train_preprocess.json'\n",
    "valid_dataset_path = './dataset/MT_SUNIBS_INZNTV/valid_preprocess.json'\n",
    "test_dataset_path = './dataset/MT_SUNIBS_INZNTV/test_preprocess.json'\n",
    "\n",
    "train_dataset = MachineTranslationDataset(train_dataset_path, tokenizer, lowercase=lower, no_special_token=no_special_token, \n",
    "                                            speaker_1_id=speaker_1_id, speaker_2_id=speaker_2_id, separator_id=separator_id,\n",
    "                                            max_token_length=max_seq_len, swap_source_target=swap_source_target)\n",
    "valid_dataset = MachineTranslationDataset(valid_dataset_path, tokenizer, lowercase=lower, no_special_token=no_special_token, \n",
    "                                            speaker_1_id=speaker_1_id, speaker_2_id=speaker_2_id, separator_id=separator_id,\n",
    "                                            max_token_length=max_seq_len, swap_source_target=swap_source_target)\n",
    "test_dataset = MachineTranslationDataset(test_dataset_path, tokenizer, lowercase=lower, no_special_token=no_special_token, \n",
    "                                            speaker_1_id=speaker_1_id, speaker_2_id=speaker_2_id, separator_id=separator_id,\n",
    "                                            max_token_length=max_seq_len, swap_source_target=swap_source_target)\n",
    "\n",
    "train_loader = GenerationDataLoader(dataset=train_dataset, model_type=model_type, tokenizer=tokenizer, max_seq_len=max_seq_len, \n",
    "                                    batch_size=train_batch_size, src_lid_token_id=src_lid, tgt_lid_token_id=tgt_lid, num_workers=8, shuffle=True)  \n",
    "valid_loader = GenerationDataLoader(dataset=valid_dataset, model_type=model_type, tokenizer=tokenizer, max_seq_len=max_seq_len, \n",
    "                                    batch_size=valid_batch_size, src_lid_token_id=src_lid, tgt_lid_token_id=tgt_lid, num_workers=8, shuffle=False)\n",
    "test_loader = GenerationDataLoader(dataset=test_dataset, model_type=model_type, tokenizer=tokenizer, max_seq_len=max_seq_len, \n",
    "                                   batch_size=test_batch_size, src_lid_token_id=src_lid, tgt_lid_token_id=tgt_lid, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d5a15-702a-4905-baba-9b80e0d8950e",
   "metadata": {},
   "source": [
    "# Test model to generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05dcbc78-d5c8-4094-84e4-dd6b0abb35c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-24 17:05:52.724648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> aku pergi ke toko obat membeli <mask> [indonesian]\n",
      "<s> aku pergi ke toko obat membeli obat.\n"
     ]
    }
   ],
   "source": [
    "inputs = ['aku pergi ke toko obat membeli <mask>']\n",
    "bart_input = tokenizer.prepare_input_for_generation(inputs, return_tensors='pt',\n",
    "                                         lang_token = '[indonesian]', decoder_lang_token='[indonesian]')\n",
    "\n",
    "bart_input.to(device)\n",
    "bart_out = model(**bart_input)\n",
    "print(tokenizer.decode(bart_input['input_ids'][0]))\n",
    "print(tokenizer.decode(bart_out.logits.topk(1).indices[:,:].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb2e5af-6aa8-40db-b331-b3cf4f8b4d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> aku menyang pasar karo <mask> [javanese]\n",
      "<s> aku menyang pasar karo tuku </s>\n"
     ]
    }
   ],
   "source": [
    "inputs = ['aku menyang pasar karo <mask>']\n",
    "bart_input = tokenizer.prepare_input_for_generation(inputs, return_tensors='pt',\n",
    "                                         lang_token = '[javanese]', decoder_lang_token='[javanese]')\n",
    "\n",
    "bart_input.to(device)\n",
    "bart_out = bart_model(**bart_input)\n",
    "print(tokenizer.decode(bart_input['input_ids'][0]))\n",
    "print(tokenizer.decode(bart_out.logits.topk(1).indices[:,:].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b37a52-c354-4bfd-ac84-e2220ff511b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> kuring ka pasar senen meuli daging <mask> [sundanese]\n",
      "<s> kuring ka pasar senen meuli daging sapi </s>\n"
     ]
    }
   ],
   "source": [
    "inputs = ['kuring ka pasar senen meuli daging <mask>']\n",
    "bart_input = tokenizer.prepare_input_for_generation(inputs, return_tensors='pt',\n",
    "                                         lang_token = '[sundanese]', decoder_lang_token='[sundanese]')\n",
    "\n",
    "bart_input.to(device)\n",
    "bart_out = bart_model(**bart_input)\n",
    "print(tokenizer.decode(bart_input['input_ids'][0]))\n",
    "print(tokenizer.decode(bart_out.logits.topk(1).indices[:,:].squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c536a51-da36-4eb1-ad8d-3709ccf04b35",
   "metadata": {},
   "source": [
    "# Test model to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7129644-069a-402f-9c5a-ff8d7ddc553f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TESTING... : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:30<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_metrics, test_hyp, test_label = evaluate(model, data_loader=test_loader, forward_fn=forward_generation, \n",
    "                                                         metrics_fn=generation_metrics_fn, model_type=model_type, \n",
    "                                                         tokenizer=tokenizer, beam_size=beam_size, \n",
    "                                                         max_seq_len=max_seq_len, is_test=True, \n",
    "                                                         device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b8d8625-b165-4a00-b232-fba3757a0ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Prediction Result ==\n",
      "                                                 hyp  \\\n",
      "0  memang aku tidak sadar akan sesuatu, tetapi bu...   \n",
      "1              mereka semuanya makan sampai kenyang.   \n",
      "2  kita ini buatan allah, diciptakan dalam kristu...   \n",
      "3  orang suci semuanya suci ; tetapi bagi orang n...   \n",
      "4  maka pergilah petrus dan yohanes kepada teman ...   \n",
      "\n",
      "                                               label  \n",
      "0  da teu terang naon - na on, tur can tangtu sim...  \n",
      "1    terus kabeh dal alah ar nepi ka sare ub euh na.  \n",
      "2  sabab urang mah darma dad am elan allah, anu g...  \n",
      "3  pikeun anu hat ena suci mah, sagala ge suci. s...  \n",
      "4  sanggeus leupas, petrus jeung yahya nep angan ...  \n",
      "\n",
      "== Model Performance ==\n",
      "           BLEU  SacreBLEU    ROUGE1    ROUGE2    ROUGEL  ROUGELsum\n",
      "count  1.000000   1.000000  1.000000  1.000000  1.000000    1.00000\n",
      "mean   1.853613   1.876446  8.022539  1.906093  7.640285    7.64969\n",
      "std         NaN        NaN       NaN       NaN       NaN        NaN\n",
      "min    1.853613   1.876446  8.022539  1.906093  7.640285    7.64969\n",
      "25%    1.853613   1.876446  8.022539  1.906093  7.640285    7.64969\n",
      "50%    1.853613   1.876446  8.022539  1.906093  7.640285    7.64969\n",
      "75%    1.853613   1.876446  8.022539  1.906093  7.640285    7.64969\n",
      "max    1.853613   1.876446  8.022539  1.906093  7.640285    7.64969\n"
     ]
    }
   ],
   "source": [
    "metrics_scores = []\n",
    "result_dfs = []\n",
    "\n",
    "metrics_scores.append(test_metrics)\n",
    "result_dfs.append(pd.DataFrame({\n",
    "    'hyp': test_hyp, \n",
    "    'label': test_label\n",
    "}))\n",
    "\n",
    "result_df = pd.concat(result_dfs)\n",
    "metric_df = pd.DataFrame.from_records(metrics_scores)\n",
    "\n",
    "print('== Prediction Result ==')\n",
    "print(result_df.head())\n",
    "print()\n",
    "\n",
    "print('== Model Performance ==')\n",
    "print(metric_df.describe())\n",
    "\n",
    "result_df.to_csv(model_dir + \"/prediction_result.csv\")\n",
    "metric_df.describe().to_csv(model_dir + \"/evaluation_result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f680f4-c4a7-4b59-b3d3-6978107e669e",
   "metadata": {},
   "source": [
    "# Fine Tuning & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c9c26d-6768-4229-8ce1-6b306e7fbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:3.4359 LR:0.00010000: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:3.4359 BLEU:26.00 SacreBLEU:27.76 ROUGE1:43.82 ROUGE2:16.77 ROUGEL:39.59 ROUGELsum:39.60 LR:0.00010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:2.9707: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) VALID LOSS:2.9707 BLEU:18.26 SacreBLEU:18.41 ROUGE1:44.99 ROUGE2:16.78 ROUGEL:40.54 ROUGELsum:40.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:2.5026 LR:0.00009000: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:2.5026 BLEU:32.25 SacreBLEU:34.05 ROUGE1:53.80 ROUGE2:25.47 ROUGEL:50.03 ROUGELsum:50.04 LR:0.00009000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:2.8121: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) VALID LOSS:2.8121 BLEU:21.00 SacreBLEU:21.10 ROUGE1:47.60 ROUGE2:20.07 ROUGEL:43.41 ROUGELsum:43.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:1.9167 LR:0.00008100: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:1.9167 BLEU:38.30 SacreBLEU:39.95 ROUGE1:61.35 ROUGE2:33.81 ROUGEL:58.19 ROUGELsum:58.19 LR:0.00008100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:2.7939: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) VALID LOSS:2.7939 BLEU:21.97 SacreBLEU:22.10 ROUGE1:48.85 ROUGE2:21.40 ROUGEL:44.71 ROUGELsum:44.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:1.4321 LR:0.00007290: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:1.4321 BLEU:45.91 SacreBLEU:47.36 ROUGE1:68.94 ROUGE2:43.75 ROUGEL:66.50 ROUGELsum:66.50 LR:0.00007290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:2.8450: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) VALID LOSS:2.8450 BLEU:22.63 SacreBLEU:22.74 ROUGE1:49.29 ROUGE2:21.90 ROUGEL:45.29 ROUGELsum:45.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:1.0360 LR:0.00006561: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:1.0360 BLEU:55.46 SacreBLEU:56.64 ROUGE1:76.38 ROUGE2:55.30 ROUGEL:74.71 ROUGELsum:74.69 LR:0.00006561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:2.9274: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 30.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) VALID LOSS:2.9274 BLEU:22.38 SacreBLEU:22.46 ROUGE1:49.10 ROUGE2:21.79 ROUGEL:45.20 ROUGELsum:45.23\n",
      "count stop: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 6) TRAIN LOSS:0.7306 LR:0.00005905: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6) TRAIN LOSS:0.7306 BLEU:65.92 SacreBLEU:66.79 ROUGE1:82.99 ROUGE2:67.11 ROUGEL:81.99 ROUGELsum:81.99 LR:0.00005905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:3.0414: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 6) VALID LOSS:3.0414 BLEU:22.77 SacreBLEU:22.89 ROUGE1:49.43 ROUGE2:22.37 ROUGEL:45.59 ROUGELsum:45.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 7) TRAIN LOSS:0.5174 LR:0.00005314: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7) TRAIN LOSS:0.5174 BLEU:75.09 SacreBLEU:75.72 ROUGE1:88.08 ROUGE2:76.75 ROUGEL:87.53 ROUGELsum:87.52 LR:0.00005314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:3.1377: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 7) VALID LOSS:3.1377 BLEU:22.95 SacreBLEU:23.07 ROUGE1:49.38 ROUGE2:22.52 ROUGEL:45.60 ROUGELsum:45.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 8) TRAIN LOSS:0.3631 LR:0.00004783: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8) TRAIN LOSS:0.3631 BLEU:82.62 SacreBLEU:83.06 ROUGE1:91.77 ROUGE2:84.02 ROUGEL:91.51 ROUGELsum:91.52 LR:0.00004783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:3.2386: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 8) VALID LOSS:3.2386 BLEU:23.14 SacreBLEU:23.23 ROUGE1:49.33 ROUGE2:22.64 ROUGEL:45.68 ROUGELsum:45.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 9) TRAIN LOSS:0.2644 LR:0.00004305: 100%|█████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9) TRAIN LOSS:0.2644 BLEU:87.60 SacreBLEU:87.92 ROUGE1:94.25 ROUGE2:88.85 ROUGEL:94.10 ROUGELsum:94.11 LR:0.00004305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:3.3427: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 9) VALID LOSS:3.3427 BLEU:23.20 SacreBLEU:23.30 ROUGE1:49.36 ROUGE2:22.49 ROUGEL:45.61 ROUGELsum:45.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 10) TRAIN LOSS:0.1967 LR:0.00003874: 100%|████████████████████████████████████████████████████████████████████████████████████| 746/746 [01:28<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10) TRAIN LOSS:0.1967 BLEU:91.17 SacreBLEU:91.41 ROUGE1:95.92 ROUGE2:92.09 ROUGEL:95.85 ROUGELsum:95.85 LR:0.00003874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALID LOSS:3.4304: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 29.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 10) VALID LOSS:3.4304 BLEU:23.17 SacreBLEU:23.27 ROUGE1:49.44 ROUGE2:22.61 ROUGEL:45.77 ROUGELsum:45.78\n",
      "count stop: 1\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "train(model, train_loader=train_loader, valid_loader=valid_loader, optimizer=optimizer, \n",
    "      forward_fn=forward_generation, metrics_fn=generation_metrics_fn, valid_criterion=valid_criterion, \n",
    "      tokenizer=tokenizer, n_epochs=n_epochs, evaluate_every=1, early_stop=early_stop, \n",
    "      grad_accum=grad_accumulate, step_size=step_size, gamma=gamma, \n",
    "      max_norm=max_norm, model_type=model_type, beam_size=beam_size,\n",
    "      max_seq_len=max_seq_len, model_dir=model_dir, exp_id=0, fp16=\"\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442293e2-628d-4fbb-acb2-8f49803120b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(model_dir + \"/best_model_0.th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fdc5583-a665-414d-acb5-17fcfc373e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TESTING... : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [01:37<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_loss, test_metrics, test_hyp, test_label = evaluate(model, data_loader=test_loader, forward_fn=forward_generation, \n",
    "                                                         metrics_fn=generation_metrics_fn, model_type=model_type, \n",
    "                                                         tokenizer=tokenizer, beam_size=beam_size, \n",
    "                                                         max_seq_len=max_seq_len, is_test=True, \n",
    "                                                         device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fa4fdd8-0364-442e-b93f-f4f668ec5bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Prediction Result ==\n",
      "                                                 hyp  \\\n",
      "0  memang pam oh alan, ku simkuring teu sadar. ta...   \n",
      "1    kabeh oge, dal alah ar nepi ka sare ub euh eun.   \n",
      "2  sabab urang teh, mahluk allah anu diciptakan k...   \n",
      "3  sabalikna, jelema - j el ema anu suci mah, kab...   \n",
      "4  ti dinya, petrus jeung yahya dib e ungk eut ke...   \n",
      "\n",
      "                                               label  \n",
      "0  da teu terang naon - na on, tur can tangtu sim...  \n",
      "1    terus kabeh dal alah ar nepi ka sare ub euh na.  \n",
      "2  sabab urang mah darma dad am elan allah, anu g...  \n",
      "3  pikeun anu hat ena suci mah, sagala ge suci. s...  \n",
      "4  sanggeus leupas, petrus jeung yahya nep angan ...  \n",
      "\n",
      "== Model Performance ==\n",
      "            BLEU  SacreBLEU     ROUGE1     ROUGE2    ROUGEL  ROUGELsum\n",
      "count   1.000000   1.000000   1.000000   1.000000   1.00000   1.000000\n",
      "mean   15.366755  15.356161  36.183704  16.636455  31.35292  31.363771\n",
      "std          NaN        NaN        NaN        NaN       NaN        NaN\n",
      "min    15.366755  15.356161  36.183704  16.636455  31.35292  31.363771\n",
      "25%    15.366755  15.356161  36.183704  16.636455  31.35292  31.363771\n",
      "50%    15.366755  15.356161  36.183704  16.636455  31.35292  31.363771\n",
      "75%    15.366755  15.356161  36.183704  16.636455  31.35292  31.363771\n",
      "max    15.366755  15.356161  36.183704  16.636455  31.35292  31.363771\n"
     ]
    }
   ],
   "source": [
    "metrics_scores = []\n",
    "result_dfs = []\n",
    "\n",
    "metrics_scores.append(test_metrics)\n",
    "result_dfs.append(pd.DataFrame({\n",
    "    'hyp': test_hyp, \n",
    "    'label': test_label\n",
    "}))\n",
    "\n",
    "result_df = pd.concat(result_dfs)\n",
    "metric_df = pd.DataFrame.from_records(metrics_scores)\n",
    "\n",
    "print('== Prediction Result ==')\n",
    "print(result_df.head())\n",
    "print()\n",
    "\n",
    "print('== Model Performance ==')\n",
    "print(metric_df.describe())\n",
    "\n",
    "result_df.to_csv(model_dir + \"/prediction_result.csv\")\n",
    "metric_df.describe().to_csv(model_dir + \"/evaluation_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
